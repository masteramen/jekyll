---
layout: post
title:  "HashMap实现原理分析（Java源码剖析）"
title2:  "HashMap实现原理分析（Java源码剖析）"
date:   2017-01-01 23:59:52  +0800
source:  "http://www.jfox.info/hashmap%e5%ae%9e%e7%8e%b0%e5%8e%9f%e7%90%86%e5%88%86%e6%9e%90java%e6%ba%90%e7%a0%81%e5%89%96%e6%9e%90.html"
fileName:  "20170101492"
lang:  "zh_CN"
published: true
permalink: "hashmap%e5%ae%9e%e7%8e%b0%e5%8e%9f%e7%90%86%e5%88%86%e6%9e%90java%e6%ba%90%e7%a0%81%e5%89%96%e6%9e%90.html"
---
{% raw %}
HashMap是Java程序员使用频率最高的用于映射(键值对)处理的数据类型。随着JDK（Java Developmet Kit）版本的更新，JDK1.8对HashMap底层的实现进行了优化，例如引入红黑树的数据结构和扩容的优化等。本文结合JDK1.7和JDK1.8的区别，深入探讨HashMap的结构实现和功能原理。

# 内部实现

搞清楚HashMap，首先需要知道HashMap是什么，即它的存储结构-字段；其次弄明白它能干什么，即它的功能实现-方法。下面我们针对这两个方面详细展开讲解。

# 存储结构-字段

从结构实现来讲，HashMap是数组+链表+红黑树（JDK1.8增加了红黑树部分）实现的，如下如所示。
![](/wp-content/uploads/2017/08/1502010397.png) 
 
   image.png 
  
 

数据底层具体存储的是什么？
从源码可知，HashMap类中有一个非常重要的字段，就是 Node[] table，即哈希桶数组，明显它是一个Node的数组。我们来看Node[JDK1.8]是何物。

    static class Node<K,V> implements Map.Entry<K,V> {
            final int hash;    //用来定位数组索引位置
            final K key;
            V value;
            Node<K,V> next;   //链表的下一个node
    
            Node(int hash, K key, V value, Node<K,V> next) { ... }
            public final K getKey(){ ... }
            public final V getValue() { ... }
            public final String toString() { ... }
            public final int hashCode() { ... }
            public final V setValue(V newValue) { ... }
            public final boolean equals(Object o) { ... }
    }
    

Node是HashMap的一个内部类，实现了Map.Entry接口，本质是就是一个映射(键值对)。上图中的每个黑色圆点就是一个Node对象。

HashMap就是使用哈希表来存储的。哈希表为解决冲突，可以采用开放地址法和链地址法等来解决问题，Java中HashMap采用了链地址法。链地址法，简单来说，就是数组加链表的结合。在每个数组元素上都一个链表结构，当数据被Hash后，得到数组下标，把数据放在对应下标元素的链表上。

具体hash算法的原理我们不深入讨论，有兴趣的同学可以参考[https://tech.meituan.com/java-hashmap.html](http://www.jfox.info/go.php?url=https://tech.meituan.com/java-hashmap.html)我们只要知道我们通过hash方法可以得到对象所在数组的下标。

我们得先了解下HashMap的几个字段。从HashMap的默认构造函数源码可知，构造函数就是对下面几个字段进行初始化，源码如下：

    /**
         * Constructs an empty <tt>HashMap</tt> with the specified initial
         * capacity and load factor.
         *
         * @param  initialCapacity the initial capacity
         * @param  loadFactor      the load factor
         * @throws IllegalArgumentException if the initial capacity is negative
         *         or the load factor is nonpositive
         */
        public HashMap(int initialCapacity, float loadFactor) {
            if (initialCapacity < 0)
                throw new IllegalArgumentException("Illegal initial capacity: " +
                                                   initialCapacity);
            if (initialCapacity > MAXIMUM_CAPACITY)
                initialCapacity = MAXIMUM_CAPACITY;
            if (loadFactor <= 0 || Float.isNaN(loadFactor))
                throw new IllegalArgumentException("Illegal load factor: " +
                                                   loadFactor);
            this.loadFactor = loadFactor;
            this.threshold = tableSizeFor(initialCapacity);
        }
    

主要就是一下几个字段：

         int threshold;             // 所能容纳的key-value对极限 
         final float loadFactor;    // 负载因子
         int modCount;  
         int size;
    

首先，Node[] table的初始化长度length(默认值是16)，Load factor为负载因子(默认值是0.75)，threshold是HashMap所能容纳的最大数据量的Node(键值对)个数。threshold = length * Load factor。也就是说，在数组定义好长度之后，负载因子越大，所能容纳的键值对个数越多。

结合负载因子的定义公式可知，threshold就是在此Load factor和length(数组长度)对应下允许的最大元素数目，超过这个数目就重新resize(扩容)，扩容后的HashMap容量是之前容量的两倍。默认的负载因子0.75是对空间和时间效率的一个平衡选择，建议大家不要修改，除非在时间和空间比较特殊的情况下，如果内存空间很多而又对时间效率要求很高，可以降低负载因子Load factor的值；相反，如果内存空间紧张而对时间效率要求不高，可以增加负载因子loadFactor的值，这个值可以大于1。

size这个字段其实很好理解，就是HashMap中实际存在的键值对数量。注意和table的长度length、容纳最大键值对数量threshold的区别。而modCount字段主要用来记录HashMap内部结构发生变化的次数，主要用于迭代的快速失败。强调一点，内部结构发生变化指的是结构发生变化，例如put新键值对，但是某个key对应的value值被覆盖不属于结构变化。

这里存在一个问题，即使负载因子和Hash算法设计的再合理，也免不了会出现拉链过长的情况，一旦出现拉链过长，则会严重影响HashMap的性能。于是，在JDK1.8版本中，对数据结构做了进一步的优化，引入了红黑树。而当链表长度太长（默认超过8）时，链表就转换为红黑树，利用红黑树快速增删改查的特点提高HashMap的性能，其中会用到红黑树的插入、删除、查找等算法。本文不再对红黑树展开讨论，想了解更多红黑树数据结构的工作原理可以参考笔者的文章
[一篇文章搞懂红黑树的原理及实现](http://www.jfox.info/go.php?url=http://www.jianshu.com/p/37c845a5add6)

# 功能实现-方法

HashMap的内部功能实现很多，本文主要从put方法的详细执行、扩容过程具有代表性的点深入展开讲解。

## 分析HashMap的put方法

HashMap的put方法执行过程可以通过下图来理解
![](/wp-content/uploads/2017/08/1502010398.png) 
 
   image.png 
  
 

①.判断键值对数组table[i]是否为空或为null，否则执行resize()进行扩容；

②.根据键值key计算hash值得到插入的数组索引i，如果table[i]==null，直接新建节点添加，转向⑥，如果table[i]不为空，转向③；

③.判断table[i]的首个元素是否和key一样，如果相同直接覆盖value，否则转向④，这里的相同指的是hashCode以及equals；

④.判断table[i] 是否为treeNode，即table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对，否则转向⑤；

⑤.遍历table[i]，判断链表长度是否大于8，大于8的话把链表转换为红黑树，在红黑树中执行插入操作，否则进行链表的插入操作；遍历过程中若发现key已经存在直接覆盖value即可；

⑥.插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold，如果超过，进行扩容。

JDK1.8HashMap的put方法源码如下:

    1 public V put(K key, V value) {
     2     // 对key的hashCode()做hash
     3     return putVal(hash(key), key, value, false, true);
     4 }
     5 
     6 final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
     7                boolean evict) {
     8     Node<K,V>[] tab; Node<K,V> p; int n, i;
     9     // 步骤①：tab为空则创建
    10     if ((tab = table) == null || (n = tab.length) == 0)
    11         n = (tab = resize()).length;
    12     // 步骤②：计算index，并对null做处理 
    13     if ((p = tab[i = (n - 1) & hash]) == null) 
    14         tab[i] = newNode(hash, key, value, null);
    15     else {
    16         Node<K,V> e; K k;
    17         // 步骤③：节点key存在，直接覆盖value
    18         if (p.hash == hash &&
    19             ((k = p.key) == key || (key != null && key.equals(k))))
    20             e = p;
    21         // 步骤④：判断该链为红黑树
    22         else if (p instanceof TreeNode)
    23             e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
    24         // 步骤⑤：该链为链表
    25         else {
    26             for (int binCount = 0; ; ++binCount) {
    27                 if ((e = p.next) == null) {
    28                     p.next = newNode(hash, key,value,null);
                            //链表长度大于8转换为红黑树进行处理
    29                     if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st  
    30                         treeifyBin(tab, hash);
    31                     break;
    32                 }
                        // key已经存在直接覆盖value
    33                 if (e.hash == hash &&
    34                     ((k = e.key) == key || (key != null && key.equals(k)))) 
    35                            break;
    36                 p = e;
    37             }
    38         }
    39         
    40         if (e != null) { // existing mapping for key
    41             V oldValue = e.value;
    42             if (!onlyIfAbsent || oldValue == null)
    43                 e.value = value;
    44             afterNodeAccess(e);
    45             return oldValue;
    46         }
    47     }
    
    48     ++modCount;
    49     // 步骤⑥：超过最大容量 就扩容
    50     if (++size > threshold)
    51         resize();
    52     afterNodeInsertion(evict);
    53     return null;
    54 }
    

## 扩容机制

扩容(resize)就是重新计算容量，向HashMap对象里不停的添加元素，而HashMap对象内部的数组无法装载更多的元素时，对象就需要扩大数组的长度，以便能装入更多的元素。当然Java里的数组是无法自动扩容的，方法是使用一个新的数组代替已有的容量小的数组，就像我们用一个小桶装水，如果想装更多的水，就得换大水桶。

我们分析下resize的源码，鉴于JDK1.8融入了红黑树，较复杂，为了便于理解我们仍然使用JDK1.7的代码，好理解一些，本质上区别不大，具体区别后文再说。

     1 void resize(int newCapacity) {   //传入新的容量
     2     Entry[] oldTable = table;    //引用扩容前的Entry数组
     3     int oldCapacity = oldTable.length;         
     4     if (oldCapacity == MAXIMUM_CAPACITY) {  //扩容前的数组大小如果已经达到最大(2^30)了
     5         threshold = Integer.MAX_VALUE; //修改阈值为int的最大值(2^31-1)，这样以后就不会扩容了
     6         return;
     7     }
     8  
     9     Entry[] newTable = new Entry[newCapacity];  //初始化一个新的Entry数组
    10     transfer(newTable);                         //！！将数据转移到新的Entry数组里
    11     table = newTable;                           //HashMap的table属性引用新的Entry数组
    12     threshold = (int)(newCapacity * loadFactor);//修改阈值
    13 }
    

这里就是使用一个容量更大的数组来代替已有的容量小的数组，transfer()方法将原有Entry数组的元素拷贝到新的Entry数组里。

     1 void transfer(Entry[] newTable) {
     2     Entry[] src = table;                   //src引用了旧的Entry数组
     3     int newCapacity = newTable.length;
     4     for (int j = 0; j < src.length; j++) { //遍历旧的Entry数组
     5         Entry<K,V> e = src[j];             //取得旧Entry数组的每个元素
     6         if (e != null) {
     7             src[j] = null;//释放旧Entry数组的对象引用（for循环后，旧的Entry数组不再引用任何对象）
     8             do {
     9                 Entry<K,V> next = e.next;
    10                 int i = indexFor(e.hash, newCapacity); //！！重新计算每个元素在数组中的位置
    11                 e.next = newTable[i]; //标记[1]
    12                 newTable[i] = e;      //将元素放在数组上
    13                 e = next;             //访问下一个Entry链上的元素
    14             } while (e != null);
    15         }
    16     }
    17 }
    

下面举个例子说明下扩容过程。假设了我们的hash算法就是简单的用key mod 一下表的大小（也就是数组的长度）。其中的哈希桶数组table的size=2， 所以key = 3、7、5，put顺序依次为 5、7、3。在mod 2以后都冲突在table[1]这里了。这里假设负载因子 loadFactor=1，即当键值对的实际大小size 大于 table的实际大小时进行扩容。接下来的三个步骤是哈希桶数组 resize成4，然后所有的Node重新rehash的过程。
![](/wp-content/uploads/2017/08/15020103981.png) 
 
   image.png 
  
 

JDK8中对扩容机制又进行了优化，涉及比较复杂的位操作，本文不深入讨论，有兴趣的读者参考文章[https://tech.meituan.com/java-hashmap.html](http://www.jfox.info/go.php?url=https://tech.meituan.com/java-hashmap.html)

# Map中各实现类的总结

Java为数据结构中的映射定义了一个接口java.util.Map，此接口主要有四个常用的实现类，分别是HashMap、Hashtable、LinkedHashMap和TreeMap，类继承关系如下图所示：
![](/wp-content/uploads/2017/08/1502010399.png)
 
 
   image.png 
  
 

下面针对各个实现类的特点做一些说明：

(1) HashMap：它根据键的hashCode值存储数据，大多数情况下可以直接定位到它的值，因而具有很快的访问速度，但遍历顺序却是不确定的。 HashMap最多只允许一条记录的键为null，允许多条记录的值为null。HashMap非线程安全，即任一时刻可以有多个线程同时写HashMap，可能会导致数据的不一致。如果需要满足线程安全，可以用 Collections的synchronizedMap方法使HashMap具有线程安全的能力，或者使用ConcurrentHashMap。

(2) Hashtable：Hashtable是遗留类，很多映射的常用功能与HashMap类似，不同的是它承自Dictionary类，并且是线程安全的，任一时间只有一个线程能写Hashtable，并发性不如ConcurrentHashMap，因为ConcurrentHashMap引入了分段锁。Hashtable不建议在新代码中使用，不需要线程安全的场合可以用HashMap替换，需要线程安全的场合可以用ConcurrentHashMap替换。

(3) LinkedHashMap：LinkedHashMap是HashMap的一个子类，保存了记录的插入顺序，在用Iterator遍历LinkedHashMap时，先得到的记录肯定是先插入的，也可以在构造时带参数，按照访问次序排序。

(4) TreeMap：TreeMap实现SortedMap接口，能够把它保存的记录根据键排序，默认是按键值的升序排序，也可以指定排序的比较器，当用Iterator遍历TreeMap时，得到的记录是排过序的。如果使用排序的映射，建议使用TreeMap。在使用TreeMap时，key必须实现Comparable接口或者在构造TreeMap传入自定义的Comparator，否则会在运行时抛出java.lang.ClassCastException类型的异常。

对于上述四种Map类型的类，要求映射中的key是不可变对象。不可变对象是该对象在创建后它的哈希值不会被改变。如果对象的哈希值发生变化，Map对象很可能就定位不到映射的位置了。

通过上面的比较，我们知道了HashMap是Java的Map家族中一个普通成员，鉴于它可以满足大多数场景的使用条件，所以是使用频度最高的一个。下文我们主要结合源码，从存储结构、常用方法分析、扩容以及安全性等方面深入讲解HashMap的工作原理。

# 小结

小结
(1) 扩容是一个特别耗性能的操作，所以当程序员在使用HashMap的时候，估算map的大小，初始化的时候给一个大致的数值，避免map进行频繁的扩容。

(2) 负载因子是可以修改的，也可以大于1，但是建议不要轻易修改，除非情况非常特殊。

(3) JDK1.8引入红黑树大程度优化了HashMap的性能。

(4) 还没升级JDK1.8的，现在开始升级吧。HashMap的性能提升仅仅是JDK1.8的冰山一角。

**参考**
JDK1.7&JDK1.8 源码。
[Java 8系列之重新认识HashMap](http://www.jfox.info/go.php?url=https://tech.meituan.com/java-hashmap.html)
CSDN博客频道，[HashMap多线程死循环问题](http://www.jfox.info/go.php?url=http://blog.csdn.net/xuefeng0707/article/details/40797085)，2014。
红黑联盟，[Java类集框架之HashMap(JDK1.8)源码剖析](http://www.jfox.info/go.php?url=http://www.2cto.com/kf/201505/401433.html)，2015。
CSDN博客频道，[ 教你初步了解红黑树](http://www.jfox.info/go.php?url=http://blog.csdn.net/v_july_v/article/details/6105630)，2010。
Java Code Geeks，[HashMap performance improvements in Java 8](http://www.jfox.info/go.php?url=http://www.javacodegeeks.com/2014/04/hashmap-performance-improvements-in-java-8.html)，2014。
Importnew，[危险！在HashMap中将可变对象用作Key](http://www.jfox.info/go.php?url=http://www.importnew.com/13384.html)，2014。
CSDN博客频道，[为什么一般hashtable的桶数会取一个素数](http://www.jfox.info/go.php?url=http://blog.csdn.net/liuqiyao_01/article/details/14475159)，2013。
{% endraw %}
